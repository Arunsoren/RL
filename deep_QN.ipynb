{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "is_python ='inline' in matplotlib.get_backend()\n",
    "if is_python: from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, img_height, img_width):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=img_height*img_width*3, out_features = 24)\n",
    "        self.fc2 = nn.LInear(in_features=24,out_features=32)\n",
    "        self.out = nn.Linear(in_features=32, out_features=2)\n",
    "     \n",
    "    def forward(self, t):\n",
    "        t = t.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        return t \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = namedtuple(\n",
    "           'Experinence',\n",
    "('state','action','next_state','reward')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Experience(2,3,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experinence(state=2, action=3, next_state=1, reward=4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self,capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory =[]\n",
    "        self.push_count = 0\n",
    "        \n",
    "    def push(self, experince):\n",
    "        if len(self.memory)< self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.push_count%self.capacity] = expeience\n",
    "        self.push_count +=1\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def can_provide_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size      \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyStratrgy():\n",
    "    def __init__(self, start, end, decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay =decay\n",
    "        \n",
    "    def get_exploration_rate(self,current_step):\n",
    "        return self.end + (self.start - self.end)*\\\n",
    "               math.exp(-1 * cueernt_step *step.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, strategy, num_actions, device):\n",
    "        self.current_step=0\n",
    "        self.strategy =strategy\n",
    "        self.num_actions = num_actions\n",
    "        self.device = device\n",
    "        \n",
    "    def select_action(self, state, policy_net):\n",
    "        rate = strategy.get_exploration_rate(self.current_step)\n",
    "        self.current_step += 1\n",
    "        \n",
    "        if rate > random.random():\n",
    "            return random.randrange(self.num_actions) #explore\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return policy_net(state).argmax(dim=1).to(device)#exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleEnvManager():\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.env = gym.make('CartPole-v0').unwrapped\n",
    "        self.env.reset()\n",
    "        self.current_screen= None\n",
    "        self.done = False\n",
    "    \n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "    \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "    \n",
    "    def render(self, mode='human'):      #render the current state to the screen\n",
    "        return self.env.render(mode) \n",
    "        \n",
    "    def num_action_available(self):\n",
    "        return self.env.action_space.n\n",
    "        \n",
    "    def take_action(self, action):\n",
    "        \n",
    "        _, reward, self.done, _ = self.env.step(action.item())\n",
    "        return torch.tensor([reward], device=self.device)\n",
    "\n",
    "    def just_starting(self):\n",
    "        return self.current_screen is None\n",
    "    \n",
    "    def get_state(self):\n",
    "        if self.just_starting() or self.done:\n",
    "            self.current_screen = self.get_processed_screen()\n",
    "            black_screen = torch.zeros_like(self.current_screen)\n",
    "            return black_screen\n",
    "        else: #end of an episode\n",
    "            s1 = self.current_screen\n",
    "            s2 = self.get_processed_screen()\n",
    "            self.current_screen =s2\n",
    "            return s2-s1\n",
    "        \n",
    "        \n",
    "    def get_screen_height(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[2]\n",
    "    \n",
    "    def get_screen_width(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[3]\n",
    "    \n",
    "    def get_processed_screen(self):\n",
    "        screen = self.render('rgb_array').transpose((2,0,1)) #pytorch expect\n",
    "        screen = self.crop_screen(screen)\n",
    "        return self.transform_screen_data(screen)\n",
    "    \n",
    "    def crop_screen(self,screen):\n",
    "        screen_height = screen.shape[1]\n",
    "        \n",
    "        #strip off top and bottom\n",
    "        top = int(screen_height*0.4)\n",
    "        bottom = int(screen_height*0.8)\n",
    "        screen = screen[:, top:bottom, :]\n",
    "        return screen\n",
    "       \n",
    "    def transform_screen_data(self, screen):\n",
    "        #conevrt to float, rescale, convert to tensor\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32)/255\n",
    "        screen = torch.from_numpy(screen)\n",
    "        \n",
    "        #use torchvision package to compose image transform\n",
    "        resize = T.Compose([\n",
    "                    T.ToPILImage()\n",
    "                    ,T.Resize((40,90))\n",
    "                    ,T.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        return resize(screen).unsqueeze(0).to(self.device) #add a batch simention\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "em = CartPoleEnvManager(device)\n",
    "em.reset()\n",
    "for i in range(5):\n",
    "    em.take_action(torch.tensor([1]))\n",
    "screen = em.get_state()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1,2,0),interpolation='none')\n",
    "plt.title('Processed Screen Example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
